{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3018469-98b5-40a8-a979-d7b0b8d74f59",
   "metadata": {},
   "source": [
    "# Natural Language Processing Using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ff1d194-250b-4b6a-80e5-e3b406663005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4664e4-0f05-41d2-b38d-7588fcb15424",
   "metadata": {},
   "source": [
    "# Word Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fc1b483-ccaa-4931-a619-64d527d9c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "716fbbca-919f-4b5a-bee7-44c099fac939",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The Natural Language Toolkit, or more commonly NLTK, is a suite of libraries and programs for symbolic and statistical natural language processing (NLP) for English written in the Python programming language. It supports classification, tokenization, stemming, tagging, parsing, and semantic reasoning functionalities.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "927b15a4-ce0f-4c3d-aa73-8368898146a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59d0cd4e-898a-4532-86d1-a032edcc3e23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Natural',\n",
       " 'Language',\n",
       " 'Toolkit',\n",
       " ',',\n",
       " 'or',\n",
       " 'more',\n",
       " 'commonly',\n",
       " 'NLTK',\n",
       " ',',\n",
       " 'is',\n",
       " 'a',\n",
       " 'suite',\n",
       " 'of',\n",
       " 'libraries',\n",
       " 'and',\n",
       " 'programs',\n",
       " 'for',\n",
       " 'symbolic',\n",
       " 'and',\n",
       " 'statistical',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'for',\n",
       " 'English',\n",
       " 'written',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Python',\n",
       " 'programming',\n",
       " 'language',\n",
       " '.',\n",
       " 'It',\n",
       " 'supports',\n",
       " 'classification',\n",
       " ',',\n",
       " 'tokenization',\n",
       " ',',\n",
       " 'stemming',\n",
       " ',',\n",
       " 'tagging',\n",
       " ',',\n",
       " 'parsing',\n",
       " ',',\n",
       " 'and',\n",
       " 'semantic',\n",
       " 'reasoning',\n",
       " 'functionalities',\n",
       " '.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cde803-5ba4-4ada-a734-3b4e0ed15cea",
   "metadata": {},
   "source": [
    "# Sentence Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b130455-8873-4851-863b-21fd63105de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "696cd26f-26b2-418e-8e1b-d97bb59c067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50d3675e-313d-4b4b-b707-55c2d7cc78f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Natural Language Toolkit, or more commonly NLTK, is a suite of libraries and programs for symbolic and statistical natural language processing (NLP) for English written in the Python programming language.',\n",
       " 'It supports classification, tokenization, stemming, tagging, parsing, and semantic reasoning functionalities.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86120e31-297d-4dc8-b1c0-9551195127c1",
   "metadata": {},
   "source": [
    "# Stopwords Removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cb635b7-e36f-4e06-8c5f-c603afb42cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc918c0d-2bb3-4394-b4ca-cb171645b118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a778bb56-0ea9-42a0-8148-d9939af64d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f37c786-56fd-45a8-850b-c3ba324e98d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " \"he's\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " \"i've\",\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " \"we've\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30e254a0-fc87-4857-be11-750cbf6c7b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_words = [i for i in words if i.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aae9c793-33ce-43b1-b3f6-9b4e736961ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a756abe1-d9d7-4958-9e04-822ce4f800cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Natural',\n",
       " 'Language',\n",
       " 'Toolkit',\n",
       " 'or',\n",
       " 'more',\n",
       " 'commonly',\n",
       " 'NLTK',\n",
       " 'is',\n",
       " 'a',\n",
       " 'suite',\n",
       " 'of',\n",
       " 'libraries',\n",
       " 'and',\n",
       " 'programs',\n",
       " 'for',\n",
       " 'symbolic',\n",
       " 'and',\n",
       " 'statistical',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'NLP',\n",
       " 'for',\n",
       " 'English',\n",
       " 'written',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Python',\n",
       " 'programming',\n",
       " 'language',\n",
       " 'It',\n",
       " 'supports',\n",
       " 'classification',\n",
       " 'tokenization',\n",
       " 'stemming',\n",
       " 'tagging',\n",
       " 'parsing',\n",
       " 'and',\n",
       " 'semantic',\n",
       " 'reasoning',\n",
       " 'functionalities']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e138984c-328b-4837-b915-fa0b763370f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words = [i for i in raw_words if i.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c52ce5a6-c9a2-4e47-b711-bcced15efe3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'Language',\n",
       " 'Toolkit',\n",
       " 'commonly',\n",
       " 'NLTK',\n",
       " 'suite',\n",
       " 'libraries',\n",
       " 'programs',\n",
       " 'symbolic',\n",
       " 'statistical',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'NLP',\n",
       " 'English',\n",
       " 'written',\n",
       " 'Python',\n",
       " 'programming',\n",
       " 'language',\n",
       " 'supports',\n",
       " 'classification',\n",
       " 'tokenization',\n",
       " 'stemming',\n",
       " 'tagging',\n",
       " 'parsing',\n",
       " 'semantic',\n",
       " 'reasoning',\n",
       " 'functionalities']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5764d921-2692-4da2-9a35-1d721a8ca26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fe724e-c79b-4afe-8ee8-0d395a90c87d",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f18a4a05-b008-48bb-b4eb-392c1f629485",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8248cc18-1f03-40d0-a75f-7cfe2f547a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "steammer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d0ac03a-5bc7-4f61-8e55-379c7614bdaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natur',\n",
       " 'languag',\n",
       " 'toolkit',\n",
       " 'commonli',\n",
       " 'nltk',\n",
       " 'suit',\n",
       " 'librari',\n",
       " 'program',\n",
       " 'symbol',\n",
       " 'statist',\n",
       " 'natur',\n",
       " 'languag',\n",
       " 'process',\n",
       " 'nlp',\n",
       " 'english',\n",
       " 'written',\n",
       " 'python',\n",
       " 'program',\n",
       " 'languag',\n",
       " 'support',\n",
       " 'classif',\n",
       " 'token',\n",
       " 'stem',\n",
       " 'tag',\n",
       " 'pars',\n",
       " 'semant',\n",
       " 'reason',\n",
       " 'function']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[steammer.stem(i.lower()) for i in filtered_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b173465-5c7e-452f-ad75-1faaa0a1038c",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2cb0101d-eedd-4f67-a64a-85fb7009e5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb2bddf2-cb62-4184-8dd7-a57b9b627baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e82e84fb-2d1e-47fb-a74e-2f4bdbd14510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fly'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma.lemmatize(\"flying\",\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ae3ffab-a0d9-47af-a791-1f5a4d3ec99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fly'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma.lemmatize(\"flew\", \"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e4f7e0dd-01aa-48c8-af56-36df0f6e6ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'functional'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma.lemmatize(\"functional\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0eafd814-9819-4b01-9fcb-c153edef852a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'functionility'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma.lemmatize(\"functionility\", \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6fae218b-a97f-467b-bc0e-cf6eed416c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(word):\n",
    "    w = word.lower()\n",
    "    for i in [\"n\", \"v\", \"a\", \"r\", \"s\"]:\n",
    "        root_word = lemma.lemmatize(w, i)\n",
    "        if len(root_word) != len(w):\n",
    "            return root_word\n",
    "    else:\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f4db6263-44fe-4169-bd1f-74af27815f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'work'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatization(\"worked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8aab541b-9a9e-4683-a6b7-045a9a617beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'program'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatization(\"Programming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "51907531-c2ff-4f1e-a2d1-1a3429e221e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_words = [lemmatization(i) for i in filtered_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2ae9d8a0-3a84-4c05-8117-8061eb7fb5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'Language',\n",
       " 'Toolkit',\n",
       " 'commonly',\n",
       " 'NLTK',\n",
       " 'suite',\n",
       " 'library',\n",
       " 'program',\n",
       " 'symbolic',\n",
       " 'statistical',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'process',\n",
       " 'NLP',\n",
       " 'English',\n",
       " 'write',\n",
       " 'Python',\n",
       " 'program',\n",
       " 'language',\n",
       " 'support',\n",
       " 'classification',\n",
       " 'tokenization',\n",
       " 'stem',\n",
       " 'tag',\n",
       " 'parse',\n",
       " 'semantic',\n",
       " 'reason',\n",
       " 'functionality']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d635b3-2e84-417a-8ee8-e3ef0dbfe132",
   "metadata": {},
   "source": [
    "# POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6272544f-7cf7-40a3-b95a-0916d0968655",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "18dc5f08-f61e-4a55-968b-da543cf5ce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Albert Einstein was born in Pune, Maharashtra, India in 1983. He completed his Masters in Data Science course from 3RI Technologies.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "328ad71c-1f7d-42a6-a767-3f5311a39655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Albert Einstein was born in Pune, Maharashtra, India in 1983. He completed his Masters in Data Science course from 3RI Technologies.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dac5a069-8839-4ba9-ae72-bab42ed04d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_2 = word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ef46d201-ba1a-4683-9d2b-51495cef927f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Albert',\n",
       " 'Einstein',\n",
       " 'was',\n",
       " 'born',\n",
       " 'in',\n",
       " 'Pune',\n",
       " ',',\n",
       " 'Maharashtra',\n",
       " ',',\n",
       " 'India',\n",
       " 'in',\n",
       " '1983',\n",
       " '.',\n",
       " 'He',\n",
       " 'completed',\n",
       " 'his',\n",
       " 'Masters',\n",
       " 'in',\n",
       " 'Data',\n",
       " 'Science',\n",
       " 'course',\n",
       " 'from',\n",
       " '3RI',\n",
       " 'Technologies',\n",
       " '.']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e10ce786-9a40-41e1-a2e4-53057a976706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5f2ff582-bb59-453a-b791-9d47f7d27413",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "74bc9586-2a10-411d-8356-9c7fae0c8a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words_2 = [i for i in words_2 if i not in punct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9d3d395e-dc5e-4e7a-80ef-7cd0bb17fe02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Albert',\n",
       " 'Einstein',\n",
       " 'was',\n",
       " 'born',\n",
       " 'in',\n",
       " 'Pune',\n",
       " 'Maharashtra',\n",
       " 'India',\n",
       " 'in',\n",
       " '1983',\n",
       " 'He',\n",
       " 'completed',\n",
       " 'his',\n",
       " 'Masters',\n",
       " 'in',\n",
       " 'Data',\n",
       " 'Science',\n",
       " 'course',\n",
       " 'from',\n",
       " '3RI',\n",
       " 'Technologies']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_words_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3865d998-c1a5-4817-8c82-668eb120f4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_pos = pos_tag(filtered_words_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c1da7ce6-8c1f-4e90-b7d0-5c05211499da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Albert', 'NNP'),\n",
       " ('Einstein', 'NNP'),\n",
       " ('was', 'VBD'),\n",
       " ('born', 'VBN'),\n",
       " ('in', 'IN'),\n",
       " ('Pune', 'NNP'),\n",
       " ('Maharashtra', 'NNP'),\n",
       " ('India', 'NNP'),\n",
       " ('in', 'IN'),\n",
       " ('1983', 'CD'),\n",
       " ('He', 'PRP'),\n",
       " ('completed', 'VBD'),\n",
       " ('his', 'PRP$'),\n",
       " ('Masters', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('Data', 'NNP'),\n",
       " ('Science', 'NNP'),\n",
       " ('course', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('3RI', 'CD'),\n",
       " ('Technologies', 'NNS')]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a86bc68-edf6-4e83-a02b-b19659cdb000",
   "metadata": {},
   "source": [
    "# NER - Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a0b13510-2b18-4876-ad8e-dfb537d00212",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5d4d6cca-7c05-4ac8-b5d2-ba0149bd4eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence2 = \"Steve Jobs was founder of Apple company, California.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e94a42e3-0782-4af1-bad7-7422ff2b9814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"168px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px\" version=\"1.1\" viewBox=\"0,0,544.0,168.0\" width=\"544px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"11.7647%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PERSON</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Steve</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"5.88235%\" y1=\"20px\" y2=\"48px\" /><svg width=\"11.7647%\" x=\"11.7647%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PERSON</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Jobs</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"17.6471%\" y1=\"20px\" y2=\"48px\" /><svg width=\"7.35294%\" x=\"23.5294%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">was</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"27.2059%\" y1=\"20px\" y2=\"48px\" /><svg width=\"13.2353%\" x=\"30.8824%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">founder</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"37.5%\" y1=\"20px\" y2=\"48px\" /><svg width=\"5.88235%\" x=\"44.1176%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">of</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"47.0588%\" y1=\"20px\" y2=\"48px\" /><svg width=\"10.2941%\" x=\"50%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">GPE</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Apple</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"55.1471%\" y1=\"20px\" y2=\"48px\" /><svg width=\"13.2353%\" x=\"60.2941%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">company</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"66.9118%\" y1=\"20px\" y2=\"48px\" /><svg width=\"4.41176%\" x=\"73.5294%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"75.7353%\" y1=\"20px\" y2=\"48px\" /><svg width=\"17.6471%\" x=\"77.9412%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">GPE</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">California</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"86.7647%\" y1=\"20px\" y2=\"48px\" /><svg width=\"4.41176%\" x=\"95.5882%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"97.7941%\" y1=\"20px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('S', [Tree('PERSON', [('Steve', 'NNP')]), Tree('PERSON', [('Jobs', 'NNP')]), ('was', 'VBD'), ('founder', 'NN'), ('of', 'IN'), Tree('GPE', [('Apple', 'NNP')]), ('company', 'NN'), (',', ','), Tree('GPE', [('California', 'NNP')]), ('.', '.')])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne_chunk(pos_tag(word_tokenize(sentence2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a6683f7b-cef8-422c-88d5-1d674c98c5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON Steve\n",
      "PERSON Jobs\n",
      "GPE Apple\n",
      "GPE California\n"
     ]
    }
   ],
   "source": [
    "for chunks in ne_chunk(pos_tag(word_tokenize(sentence2))):\n",
    "    if hasattr(chunks, \"label\"):\n",
    "        print(chunks.label(), \" \".join(i[0] for i in chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b9e9bf-584e-49e7-9411-bc94b4f84edb",
   "metadata": {},
   "source": [
    "# Synonums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6078e730-3a21-4f4c-b12b-3ac3ebde2e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a2948753-85e8-4a9d-af49-5c7e3cf64339",
   "metadata": {},
   "outputs": [],
   "source": [
    "syns = wordnet.synsets(\"bank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f9880b88-4aaa-42e3-9c6b-c7b35a25404d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('bank.n.01'),\n",
       " Synset('depository_financial_institution.n.01'),\n",
       " Synset('bank.n.03'),\n",
       " Synset('bank.n.04'),\n",
       " Synset('bank.n.05'),\n",
       " Synset('bank.n.06'),\n",
       " Synset('bank.n.07'),\n",
       " Synset('savings_bank.n.02'),\n",
       " Synset('bank.n.09'),\n",
       " Synset('bank.n.10'),\n",
       " Synset('bank.v.01'),\n",
       " Synset('bank.v.02'),\n",
       " Synset('bank.v.03'),\n",
       " Synset('bank.v.04'),\n",
       " Synset('bank.v.05'),\n",
       " Synset('deposit.v.02'),\n",
       " Synset('bank.v.07'),\n",
       " Synset('trust.v.01')]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "40f9e586-1831-4891-ae2c-4532c51beaf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bank.n.01'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syns[0].name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f4e6ec23-eaf3-4540-9467-9ccb40606a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bank'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syns[0].lemmas()[0].name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "33220bf0-e4f0-4d20-8835-3316878bb5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sloping land (especially the slope beside a body of water)'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syns[0].definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "16a5251b-371d-48f5-bf96-33c2b3077495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['they pulled the canoe up on the bank',\n",
       " 'he sat on the bank of the river and watched the currents']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syns[0].examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f5426f66-9f9e-4776-94f2-ab8dcf07ecdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bank\n",
      "sloping land (especially the slope beside a body of water)\n",
      "['they pulled the canoe up on the bank', 'he sat on the bank of the river and watched the currents']\n",
      "================================================================================\n",
      "depository_financial_institution\n",
      "a financial institution that accepts deposits and channels the money into lending activities\n",
      "['he cashed a check at the bank', 'that bank holds the mortgage on my home']\n",
      "================================================================================\n",
      "bank\n",
      "a long ridge or pile\n",
      "['a huge bank of earth']\n",
      "================================================================================\n",
      "bank\n",
      "an arrangement of similar objects in a row or in tiers\n",
      "['he operated a bank of switches']\n",
      "================================================================================\n",
      "bank\n",
      "a supply or stock held in reserve for future use (especially in emergencies)\n",
      "[]\n",
      "================================================================================\n",
      "bank\n",
      "the funds held by a gambling house or the dealer in some gambling games\n",
      "['he tried to break the bank at Monte Carlo']\n",
      "================================================================================\n",
      "bank\n",
      "a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force\n",
      "[]\n",
      "================================================================================\n",
      "savings_bank\n",
      "a container (usually with a slot in the top) for keeping money at home\n",
      "['the coin bank was empty']\n",
      "================================================================================\n",
      "bank\n",
      "a building in which the business of banking transacted\n",
      "['the bank is on the corner of Nassau and Witherspoon']\n",
      "================================================================================\n",
      "bank\n",
      "a flight maneuver; aircraft tips laterally about its longitudinal axis (especially in turning)\n",
      "['the plane went into a steep bank']\n",
      "================================================================================\n",
      "bank\n",
      "tip laterally\n",
      "['the pilot had to bank the aircraft']\n",
      "================================================================================\n",
      "bank\n",
      "enclose with a bank\n",
      "['bank roads']\n",
      "================================================================================\n",
      "bank\n",
      "do business with a bank or keep an account at a bank\n",
      "['Where do you bank in this town?']\n",
      "================================================================================\n",
      "bank\n",
      "act as the banker in a game or in gambling\n",
      "[]\n",
      "================================================================================\n",
      "bank\n",
      "be in the banking business\n",
      "[]\n",
      "================================================================================\n",
      "deposit\n",
      "put into a bank account\n",
      "['She deposits her paycheck every month']\n",
      "================================================================================\n",
      "bank\n",
      "cover with ashes so to control the rate of burning\n",
      "['bank a fire']\n",
      "================================================================================\n",
      "trust\n",
      "have confidence or faith in\n",
      "['We can trust in God', 'Rely on your friends', 'bank on your good education', \"I swear by my grandmother's recipes\"]\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(syns)):\n",
    "    print(syns[i].lemmas()[0].name())\n",
    "    print(syns[i].definition())\n",
    "    print(syns[i].examples())\n",
    "    print(\"==\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a711e980-2974-44b5-b2a0-2e6a1374aab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plan\n",
      "a series of steps to be carried out or goals to be accomplished\n",
      "['they drew up a six-step plan', 'they discussed plans for a new bond issue']\n",
      "================================================================================\n",
      "program\n",
      "a system of projects or services intended to meet a public need\n",
      "['he proposed an elaborate program of public works', 'working mothers rely on the day care program']\n",
      "================================================================================\n",
      "broadcast\n",
      "a radio or television show\n",
      "['did you see his program last night?']\n",
      "================================================================================\n",
      "platform\n",
      "a document stating the aims and principles of a political party\n",
      "['their candidate simply ignored the party platform', 'they won the election even though they offered no positive program']\n",
      "================================================================================\n",
      "program\n",
      "an announcement of the events that will occur as part of a theatrical or sporting event\n",
      "[\"you can't tell the players without a program\"]\n",
      "================================================================================\n",
      "course_of_study\n",
      "an integrated course of academic studies\n",
      "['he was admitted to a new program at the university']\n",
      "================================================================================\n",
      "program\n",
      "(computer science) a sequence of instructions that a computer can interpret and execute\n",
      "['the program required several hundred lines of code']\n",
      "================================================================================\n",
      "program\n",
      "a performance (or series of performances) at a public presentation\n",
      "['the program lasted more than two hours']\n",
      "================================================================================\n",
      "program\n",
      "arrange a program of or for\n",
      "['program the 80th birthday party']\n",
      "================================================================================\n",
      "program\n",
      "write a computer program\n",
      "[]\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "syns2 = wordnet.synsets(\"program\")\n",
    "for i in range(len(syns2)):\n",
    "    print(syns2[i].lemmas()[0].name())\n",
    "    print(syns2[i].definition())\n",
    "    print(syns2[i].examples())\n",
    "    print(\"==\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417e2b1e-2c5b-459d-af18-e67ef7939c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
